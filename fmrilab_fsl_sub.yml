---
method: sge
queues: # Queue definitions (Partitions in SLURM)
  nvidia.q: # Queue name
    time: 18000 # Maximum job rum time (minutes)
    max_size: 250 # Maximum memory per job (GB)
    slot_size: 48 # Maximum memory per CPU core (GB)
    max_slots: 20 # Maximum number of threads per job (e.g. number of CPU cores)
    copros: # Available coprocessors
      cuda: # Coprocessor name (same as configuration above)
        max_quantity: 4 # Number of devices available per job (e.g. number of devices on a single node)
        classes: # List of available classes as defined in the coproc_opts section 'class' keys
          - K
          - P
          - V
    parallel_envs: # List of available parallel environments - remove for SLURM clusters
      - openmp
    map_ram: true  # Split jobs over multiple slots when requesting more RAM than available in a single slot?
    priority: 1 # Priority of queue, higher numbers win
    group: 0 # Group of queue - groups variations of a queue, the 'priority' decides which variant to use
  all.q:
    time: 10080
    max_size: 36
    slot_size: 16
    max_slots: 20
    parallel_envs: # List of available parallel environments - remove for SLURM clusters
      - openmp
      - make
      - smp
      - mpi
    priority: 1
    group: 2
    default: True